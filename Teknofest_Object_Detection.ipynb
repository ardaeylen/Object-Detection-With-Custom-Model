{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('/content/drive/MyDrive/Data.xlsx')\n",
    "\n",
    "df.drop(df.index[(df[\"Sınıf\"] == \"Safra kesesi taşı\")],axis=0,inplace=True)\n",
    "'''\n",
    "df.drop(df.index[(df[\"Sınıf\"] == \"Kolon\")],axis=0,inplace=True)  \n",
    "df.drop(df.index[(df[\"Sınıf\"] == \"Pankreas\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Sınıf\"] == \"Böbrek-Mesane\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Sınıf\"] == \"Abdominal Aorta\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Sınıf\"] == \"Safra Kesesi\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Sınıf\"] == \"Apandiks\")],axis=0,inplace=True)\n",
    "'''\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df.info\n",
    "\n",
    "a = df.groupby('Sınıf').size()\n",
    "print(a)\n",
    "sizes = [1200,1200,1200,1200,1200,1200,1200]\n",
    "\n",
    "!pip install pydicom\n",
    "\n",
    "\n",
    "df['Sınıf'] = df['Sınıf'].map({'Akut apandisit ile uyumlu':1, 'Apendikolit':1, \n",
    "                               'Akut kolesistit ile uyumlu':2, \n",
    "                               'Akut pankreatit ile uyumlu':3,\n",
    "                               'Böbrek taşı':4, 'Üreter taşı':4, \n",
    "                               'Akut divertikülit ile uyumlu':5, 'Kalsifiye divertikül':5, \n",
    "                               'Abdominal aort diseksiyon':6, 'Abdominal aort anevrizma':6,\n",
    "                               'Kolon':0, 'Pankreas':0, 'Böbrek-Mesane':0, 'Abdominal Aorta':0,'Safra Kesesi':0, 'Apandiks':0 })\n",
    "\n",
    "#Parsing Coordinates\n",
    "def parse_coordinates(coordinate_string):\n",
    "  if pd.isnull(coordinate_string):\n",
    "    left_x,left_y,right_x,right_y = 0,0,0,0  \n",
    "    \n",
    "  else:\n",
    "    left,right = coordinate_string.split('-')\n",
    "    left_x,left_y = left.split(',')\n",
    "    right_x,right_y = right.split(',')\n",
    "    \n",
    "  return np.array([int(left_x),int(left_y),int(right_x),int(right_y)],dtype=np.float16)\n",
    "\n",
    "\n",
    "#Reading dicom images, corresponding labels and coordinates to that images\n",
    "import zipfile \n",
    "import pydicom\n",
    "import math\n",
    "from collections.abc import Iterable\n",
    "import pandas\n",
    "x =[]\n",
    "y =[]\n",
    "coordinates = []\n",
    "def read_dicom(img_path, colormap = None, extra_brightness=0):\n",
    "  ds = pydicom.dcmread(img_path)\n",
    "  shape = ds.pixel_array.shape\n",
    "  target = 255\n",
    "\n",
    "  # Convert to float to avoid overflow or underflow losses.\n",
    "  image_2d = ds.pixel_array.astype(np.float16)\n",
    "  img_data = image_2d\n",
    "  multival = isinstance(ds.WindowCenter, Iterable)\n",
    "  if multival:\n",
    "      scale_center = -ds.WindowCenter[0]\n",
    "  else:\n",
    "      scale_center = -ds.WindowCenter\n",
    "  intercept = scale_center+ds.RescaleIntercept+extra_brightness\n",
    "  image_2d += intercept\n",
    "\n",
    "  # Rescaling grey scale between 0-255\n",
    "  image_2d_scaled = (np.maximum(image_2d,0) / image_2d.max()) * 255.0\n",
    "  print(f\"after scaling to 0-255, min: {image_2d_scaled.min()}, max: {image_2d_scaled.max()}\")\n",
    "\n",
    "  \n",
    "  # Convert to uint\n",
    "  #image_2d_scaled = np.uint8(image_2d_scaled)\n",
    "  return image_2d_scaled\n",
    "\n",
    "\n",
    "\n",
    "training_zip = zipfile.ZipFile(\"/content/drive/MyDrive/Training.zip\",mode='r')\n",
    "print(zipfile)\n",
    "with training_zip as zipfile:\n",
    "  for index,row in df.iterrows():\n",
    "    if sizes[row['Sınıf']] > 0:\n",
    "      new_image_path = zipfile.extract('Training/'+str(row['Olgu Numarası'])+'/'+str(row['Kesit Numarası'])+'.dcm','/content/sample_data/images')\n",
    "      print(new_image_path) \n",
    "      x.append(read_dicom(new_image_path)) \n",
    "      y.append(row['Sınıf'])\n",
    "      coordinates.append(parse_coordinates(row['Koordinatlar']))\n",
    "      sizes[row['Sınıf']] = sizes[row['Sınıf']] - 1  \n",
    "\n",
    "\n",
    "print(str(len(x))+'----------------'+str(len(y))+'-----'+str(len(coordinates))) \n",
    "print(type(x))         \n",
    "    \n",
    "\n",
    "#Basically, you need to reshape your data to (n_images, x_shape, y_shape, channels).\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "INPUT_SIZE = (512,512)\n",
    "\n",
    "def preprocess_dataset(image,height,width,i):\n",
    "  coordinates[i][0] = coordinates[i][0]*512/width\n",
    "  coordinates[i][2] = coordinates[i][2]*512/width\n",
    "  \n",
    "  coordinates[i][1] = coordinates[i][1]*512/height\n",
    "  coordinates[i][3] = coordinates[i][3]*512/height\n",
    "    \n",
    "  image = tf.image.resize(image, (INPUT_SIZE[0], INPUT_SIZE[1]))\n",
    "  return (image)\n",
    "for i in range(0,len(x)):\n",
    "  x[i] =preprocess_dataset(x[i].reshape(x[i].shape[0],x[i].shape[1],1),x[i].shape[0],x[i].shape[1],i)\n",
    "\n",
    "\n",
    "#scale the bounding box coordinates relative to the spatial\n",
    "# dimensions of the input image\n",
    "\n",
    "for i in range(0,len(coordinates)):\n",
    "  coordinates[i] = coordinates[i]/512.0\n",
    "print(coordinates[1])  \n",
    "\n",
    "bboxes = np.array(coordinates)\n",
    "print(bboxes.shape)\n",
    "\n",
    "labels = np.array(y).reshape(8400,1)\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "plt.Figure(figsize=(14,14))\n",
    "plt.imshow(x[8399][:,:,-1])\n",
    "'''\n",
    "\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split = train_test_split(x, labels, bboxes,test_size=0.20, random_state=42)\n",
    "# unpack the data split\n",
    "(x_train, x_test) = split[:2]\n",
    "(trainLabels, testLabels) = split[2:4]\n",
    "(trainBBoxes, testBBoxes) = split[4:6]\n",
    "\n",
    "\n",
    "\n",
    "# construct a dictionary for our target training outputs\n",
    "trainTargets = {\n",
    "\t\"class_label\": np.array(trainLabels),\n",
    "\t\"bounding_box\": np.array(trainBBoxes)\n",
    "}\n",
    "# construct a second dictionary, this one for our target testing\n",
    "# outputs\n",
    "testTargets = {\n",
    "\t\"class_label\": np.array(testLabels),\n",
    "\t\"bounding_box\": np.array(testBBoxes)\n",
    "}\n",
    "\n",
    "import tensorflow as tf\n",
    "from os import name\n",
    "from keras.backend import shape\n",
    "import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dropout,Dense,Flatten,MaxPooling2D,Conv2D,AveragePooling2D\n",
    "#alexNetHEAD\n",
    "alexNet = keras.Input(shape=(512,512,1))\n",
    "\n",
    "\n",
    "alexNet1 = Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding=\"same\")(alexNet)\n",
    "alexNet2 = AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(alexNet1)\n",
    "\n",
    "alexNet3 = Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid')(alexNet2)\n",
    "alexNet4 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(alexNet3)\n",
    "\n",
    "#alexNet6 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(alexNet5)\n",
    "\n",
    "flattenLayer = (Flatten())(alexNet4)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='SGD', metrics=['accuracy'])\n",
    "ardaNetModel = Model(alexNet,flattenLayer)\n",
    "\n",
    "tf.keras.utils.plot_model(ardaNetModel)\n",
    "\n",
    "from tensorflow.keras.layers import Dropout,Dense,Flatten\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "'''bboxHeaddense1 = Dense(96, activation='relu')(flattenLayer)\n",
    "bboxHeaddense2 = Dense(96, activation='relu')(bboxHeaddense1)\n",
    "bboxHeaddense3 = Dense(96, activation='relu')(bboxHeaddense2)\n",
    "bboxHeaddense4 = Dense(96, activation='relu')(bboxHeaddense3)\n",
    "bboxHeaddense5 = Dense(96, activation='relu')(bboxHeaddense4)\n",
    "bboxHeaddense6 = Dense(96, activation='relu')(bboxHeaddense5)\n",
    "bboxHeaddense7 = Dense(96, activation='relu')(bboxHeaddense6)\n",
    "bboxHeaddense8 = Dense(96, activation='relu')(bboxHeaddense7)\n",
    "bboxHeaddense9 = Dense(4, activation=\"sigmoid\",\n",
    "\tname=\"bounding_box\")(bboxHeaddense8)'''\n",
    "# construct a second fully-connected layer head, this one to predict\n",
    "# the class label\n",
    "softmaxdense1 = Dense(84, activation='tanh')(flattenLayer)\n",
    "softmaxHead = Dense(7, activation=\"softmax\",name=\"class_label\")(softmaxdense1)\n",
    "# put together our model which accept an input image and then output\n",
    "# bounding box coordinates and a class label\n",
    "model = Model(\n",
    "\tinputs=alexNet,\n",
    "\toutputs=(bboxHeaddense9, softmaxHead))\n",
    "\n",
    "losses = {\n",
    "\t\"class_label\": \"SparseCategoricalCrossentropy\",\n",
    "\t\"bounding_box\": \"mean_squared_error\",\n",
    "}\n",
    "model.compile(loss=losses, optimizer='adam', metrics=[\"accuracy\"])\n",
    "tf.keras.utils.plot_model(model)\n",
    "\n",
    "\n",
    "'''from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "strtfdKfold = StratifiedKFold(n_splits = 10)\n",
    "kfold = strtfdKfold.split()'''\n",
    "\n",
    "history = model.fit(np.array(x_train), trainTargets,batch_size=64,validation_split=0.1,epochs=10,verbose=1)\n",
    "\n",
    "#model.fit(np.array(x_train),np.array(y_train),batch_size = 64 ,epochs=20, validation_split = 0.1) \n",
    "\n",
    "\n",
    "\n",
    "#model.save('/content/drive/MyDrive/DeepLearningModel')\n",
    "\n",
    "model.evaluate(np.array(x_test),testTargets,batch_size=64)\n",
    "\n",
    "predictions = model.predict(np.array(x_test))\n",
    "\n",
    "class_predictions = np.array(predictions[1])\n",
    "bbox_predictions = np.array(predictions[0])\n",
    "\n",
    "print(len(predictions[1][1]))\n",
    "\n",
    "model = tf.keras.models.load_model('/content/drive/MyDrive/DeepLearningModel')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 2, random_state = 42,max_features=4)\n",
    "\n",
    "rf.fit(x_test, testBBoxes)\n",
    "\n",
    "bbox_predictions = rf.predict(bbox_predictions)\n",
    "\n",
    "class_predictions = np.argmax(class_predictions, axis=1)\n",
    "print(class_predictions)\n",
    "\n",
    "\n",
    "#Determining f1-scores\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(testLabels,class_predictions,average='weighted')\n",
    "\n",
    "#Determining iou (intersection over union)\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\t# compute the intersection over union by taking the intersection\n",
    "\t# area and dividing it by the sum of prediction + ground-truth\n",
    "\t# areas - the interesection area\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\t# return the intersection over union value\n",
    "\treturn iou\n",
    "\n",
    "average = 0\n",
    "for i in range(0,len(testBBoxes)):\n",
    "  if bbox_predictions[i][0] == 0.0  or testBBoxes[i][0] == 0.0:\n",
    "    continue\n",
    "  iou = bb_intersection_over_union(testBBoxes[i]*512.0,bbox_predictions[i]*512.0)\n",
    "  print('actual values :'+str(testBBoxes[i]*512)+'-----------Predicted Values:'+str(bbox_predictions[i]*512))\n",
    "  average = average + iou\n",
    "  print(iou)\n",
    "print('average iou:')\n",
    "print(average/len(testBBoxes))  \n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion Matrix',cmap=plt.cm.Blues):\n",
    "  plt.imshow(cm,interpolation='nearest',cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(classes))\n",
    "  plt.xticks(tick_marks,classes,rotation=45)\n",
    "  plt.yticks(tick_marks,classes)\n",
    "\n",
    "  if normalize:\n",
    "    cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "    print('Normalized Confusion Matrix')\n",
    "  else:\n",
    "    print('Confusion matrix without normalization')\n",
    "  print(cm)\n",
    "\n",
    "  thresh = cm.max()/2\n",
    "\n",
    "  for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
    "    plt.text(j,i,cm[i,j],horizontalalignment='center',color='white' if cm[i,j]>thresh else 'black')\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel(\"True Label\")\n",
    "  plt.xlabel(\"Predicted Label\")\n",
    "\n",
    "\n",
    "classes = ['Kolon,Pankreas,Böbrek-Mesane,Abdominal Aorta,Safra Kesesi,Apandiks',\n",
    "          'Akut apandisit ile uyumlu,Apendikolit', \n",
    "          'Akut kolesistit ile uyumlu', \n",
    "          'Akut pankreatit ile uyumlu',\n",
    "          'Böbrek taşı,Üreter taşı', \n",
    "          'Akut divertikülit ile uyumlu,Kalsifiye divertikül', \n",
    "          'Abdominal aort diseksiyon,Abdominal aort anevrizma']\n",
    "cm = confusion_matrix(testTargets['class_label'],class_predictions)\n",
    "plot_confusion_matrix(cm,classes,title='Confusion Matrix')           \n",
    "\n",
    "def get_confusion_matrix_values(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return(cm[0][0], cm[0][1], cm[1][0], cm[1][1])\n",
    "\n",
    "TP, FP, FN, TN = get_confusion_matrix_values(x_test, x_pred)\n",
    "\n",
    "acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "plot_confusion_matrix(slf_4, X_test, y_test, normalize='true', cmap=plt.cm.Blues, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
